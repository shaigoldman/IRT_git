{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import statsmodels.api as sm\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = 24\n",
    "nsess = 24\n",
    "nlist = 24*nsess\n",
    "outputs = np.arange(ll)\n",
    "lists = np.arange(nlist)\n",
    "irt_lags = 4\n",
    "w2v_path = '/home1/shai.goldman/IRT_git/Scripts/Resources/w2v.mat'\n",
    "w2v = sio.loadmat(w2v_path)['w2v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    \n",
    "    x = pd.read_json(file_name)\n",
    "\n",
    "    # convert data stats to pandas dfs with columns for\n",
    "    # output position and rows for list number\n",
    "    data = {}\n",
    "    for key in x.keys():\n",
    "        data[key] = np.array([i for i in x[key].values])\n",
    "        if len(data[key].shape) > 1:\n",
    "            data[key] = np.pad(data[key], [(0,0), (0,ll-data[key].shape[1])], mode='edge')\n",
    "            data[key] = pd.DataFrame(data[key], columns=outputs, index=lists)\n",
    "        else:\n",
    "            data[key] = pd.Series(data[key], index=lists)\n",
    "    # I prefer the old naming convention for 'recalls' matrix\n",
    "    data['recalls'] = data.pop('serialpos')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lags(data):\n",
    "    # calc serial lags\n",
    "    prev_rec = data['recalls'].loc[:, :ll-2]\n",
    "    prev_rec.columns = range(1,ll)\n",
    "    return data['recalls'] - prev_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strech_intrus(data):\n",
    "    \n",
    "    data = data.copy()\n",
    "    \n",
    "    # remove all recalls after the first intrusion in a list\n",
    "    first_intrus = pd.Series([list(i).index(-1) if -1 in i\n",
    "                                 else len(i) for i in data['recalls'].values],\n",
    "                                index = lists\n",
    "                               )\n",
    "\n",
    "    for ls in data['recalls'].index:\n",
    "        fi = first_intrus.loc[ls]\n",
    "        data['recalls'].loc[ls, fi:] = 0\n",
    "        data['times'].loc[ls, fi:] = 0\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_irts(data):\n",
    "    # calc irts\n",
    "    prev_times = data['times'].loc[:,:ll-2].astype(float)\n",
    "    prev_times.columns = range(1, ll)\n",
    "\n",
    "    irts = data['times'] - prev_times\n",
    "    irts[irts<=0] = np.nan\n",
    "    return irts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prev_irts(data, lags=irt_lags):\n",
    "    # include prev irts into the data df\n",
    "    \n",
    "    for lag in range(1,lags+1):\n",
    "        # shift all the irts by the lag\n",
    "        prev_irts = data['irt'].loc[:, :ll-lag-1].copy()\n",
    "        prev_irts.columns = (outputs+lag)[:-lag]\n",
    "        # insert nans for outputs before the first lag\n",
    "        for output in range(lag):\n",
    "            prev_irts[output] = np.nan\n",
    "        # resort columns since we added the first outputs to the end\n",
    "        prev_irts = prev_irts[sorted(prev_irts.columns)]\n",
    "        # input to data array\n",
    "        data[f'irt-{lag}'] = prev_irts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sem_sim(a, b):\n",
    "    \"\"\" helper func for finding semantic sims. \"\"\"\n",
    "    if a <= 0 or b <= 0:\n",
    "        return np.nan\n",
    "    # the -1 is very important because of 0 indexing in python vs matlab\n",
    "    # they originally started the rec_nos from index 1 when the lab was\n",
    "    # matlab and to have a w2v matrix its going to start from index 0 in python\n",
    "    return w2v[a-1, b-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sems(data):\n",
    "    # calc semantic similarities\n",
    "    sims = [[sem_sim(row.loc[i-1], no) \n",
    "              if i>0 else np.nan\n",
    "              for i, no in row.iteritems()]\n",
    "             for r, row in data['rec_nos'].iterrows()]\n",
    "    return pd.DataFrame(sims, index=lists, columns=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_data(data, irt_lags=irt_lags):\n",
    "    \"\"\" Add many important details to the data. \"\"\"\n",
    "    \n",
    "    data = data.copy()\n",
    "    \n",
    "    data['lag'] = get_lags(data)\n",
    "    \n",
    "    # set all repeats as intrusions\n",
    "    data['recalls'][data['lag']==0] = -1\n",
    "    \n",
    "    # remove all recs after an intrus\n",
    "    data = strech_intrus(data)\n",
    "    \n",
    "    data['irt'] = get_irts(data)\n",
    "    add_prev_irts(data, lags=irt_lags)\n",
    "    \n",
    "    # calc total recalls per list\n",
    "    data['total_recalls'] = pd.Series(\n",
    "        [r[r>0].size for i, r in data['recalls'].iterrows()],\n",
    "        index=lists\n",
    "    )\n",
    "    \n",
    "    data['sem'] = get_sems(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_for_ols(data):\n",
    "    # prepare data for OLS modeling by flattening it\n",
    "    \n",
    "    #-----flatten data----#\n",
    "    flat_data = {}\n",
    "    for key in data:\n",
    "        if len(data[key].shape) > 1:\n",
    "            flat_data[key] = data[key].values.flatten()\n",
    "        else:\n",
    "            flat_data[key] = np.repeat(data[key], ll).values.flatten()\n",
    "\n",
    "    flat_data = pd.DataFrame(flat_data)\n",
    "    \n",
    "    # include output pos as a variable\n",
    "    flat_data['output_pos'] = np.repeat([outputs], nlist, axis=0).flatten()\n",
    "\n",
    "    #-----filter data----#\n",
    "    # remove keys that wont go into the model\n",
    "    for key in ['pres_words', 'pres_nos', 'rec_words',\n",
    "                'rec_nos', 'recalled', 'times', 'intrusions',\n",
    "                'subject', 'good_trial', 'recalls'\n",
    "               ]:\n",
    "        flat_data.pop(key)\n",
    "\n",
    "    # remove all nans in prep for modeling\n",
    "    for key in flat_data:\n",
    "        flat_data = flat_data[~np.isnan(flat_data[key])]\n",
    "        \n",
    "    #----adjust some variables for the model----#\n",
    "    # output position is inverted\n",
    "    flat_data['output_pos'] = flat_data['output_pos'].astype(float)\n",
    "    flat_data['output_pos'] = (ll-flat_data['output_pos']) ** -1\n",
    "    # total recalls is normalized\n",
    "    flat_data['total_recalls'] /= ll\n",
    "    # lag is taken as ln(|lag|)\n",
    "    flat_data['lag'] = np.log(np.abs(flat_data['lag']))\n",
    "    \n",
    "    # include lag sim interaction\n",
    "    flat_data['lag_sem'] = flat_data['lag'] * flat_data['sem']\n",
    "    \n",
    "    return flat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(flat_data):\n",
    "    X = sm.add_constant(flat_data)\n",
    "    y = X.pop('irt')\n",
    "\n",
    "    model = sm.OLS(y, X)\n",
    "    return model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(file_name, irt_lags=irt_lags):\n",
    "    data = load_data(file_name)\n",
    "    data = detailed_data(data, irt_lags=irt_lags)\n",
    "    flat_data = prep_data_for_ols(data)\n",
    "    return fit_model(flat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get behavioral data for ltpFR2 all subjects\n",
    "path = '/data/eeg/scalp/ltp/ltpFR2/behavioral/data/'\n",
    "files = [f for f in glob(path+'beh_data_LTP*.json') if 'incomplete' not in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a190f1fcb1c4326b3776f55ea41ca74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=98.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lags = range(1,10)\n",
    "aics = []\n",
    "bics = []\n",
    "for file in tqdm(files):\n",
    "    subj = file.split('LTP')[1].replace('.json', '')\n",
    "    models = [get_model(file, lag) for lag in lags]\n",
    "    aics.append(pd.Series([m.aic for m in models], index=lags, name=subj))\n",
    "    bics.append(pd.Series([m.bic for m in models], index=lags, name=subj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "aics = pd.concat(aics)\n",
    "bics = pd.concat(bics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_env",
   "language": "python",
   "name": "py3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
